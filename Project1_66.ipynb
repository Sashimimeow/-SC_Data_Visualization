{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sashimimeow/-SC_Data_Visualization/blob/main/Project1_66.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3f0f914",
      "metadata": {
        "id": "e3f0f914"
      },
      "source": [
        "# Text Analytics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f8afa7f",
      "metadata": {
        "id": "6f8afa7f"
      },
      "source": [
        "<img src=\"https://www.datanami.com/wp-content/uploads/2014/06/text-analytics.png\" width=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7866bdbc",
      "metadata": {
        "id": "7866bdbc"
      },
      "source": [
        "## Due Date: Sunday, October 1, 2023\n",
        "<br>\n",
        "<span style=\"color:red\">NOTE: There are always last minute issues submitting the case studies. DO NOT WAIT UNTIL THE LAST MINUTE!</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "830d61bd",
      "metadata": {
        "id": "830d61bd"
      },
      "source": [
        "## List team members:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f280656e",
      "metadata": {
        "id": "f280656e"
      },
      "source": [
        "1. <Name> <ID> <Email>\n",
        "2. <Name> <ID> <Email>\n",
        "3. <Name> <ID> <Email>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3306068f",
      "metadata": {
        "id": "3306068f"
      },
      "source": [
        "**NOTE1**: Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost\n",
        "\n",
        "**NOTE2**: Create a slide presentation once finished, convert to pdf format, and turn in by one group member only\n",
        "<br>A list of documents to turn in: 1) Jupyter notebook containing results and 2) A set of slides in pdf format"
      ]
    },
    {
      "cell_type": "raw",
      "id": "7d719e86",
      "metadata": {
        "id": "7d719e86"
      },
      "source": [
        "!pip3 install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1e236d1b",
      "metadata": {
        "id": "1e236d1b"
      },
      "outputs": [],
      "source": [
        "# Load these libraries\n",
        "import json\n",
        "import pprint\n",
        "import pandas as pd\n",
        "from io import StringIO # using StringIO to prevent ValueError\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import urllib.request\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6b4adb1",
      "metadata": {
        "id": "f6b4adb1"
      },
      "source": [
        "## Problem 1: Working with Twitter Data and JSON file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b90b2963",
      "metadata": {
        "id": "b90b2963"
      },
      "source": [
        "We are working with a Twitter dataset in JSON format from `thailand_tweets.txt`.<br>\n",
        "The tweets were scraped using \"Thailand\" keyword on August 31, 2022.<br>\n",
        "We are going to examine the dataset and retrieve information from the JSON file.\n",
        "Most Twitter datasets provide only Tweet ID where we can retrieve tweets from tweet ID as follow.\n",
        "```\n",
        "twitter.com/anyuser/status/<tweet_id>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c5915cc",
      "metadata": {
        "id": "9c5915cc"
      },
      "source": [
        "#### Read JSON file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6b52d1f",
      "metadata": {
        "scrolled": false,
        "id": "a6b52d1f"
      },
      "outputs": [],
      "source": [
        "# read the file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cca51f21",
      "metadata": {
        "id": "cca51f21"
      },
      "outputs": [],
      "source": [
        "# inspect the file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec2115fb",
      "metadata": {
        "id": "ec2115fb"
      },
      "source": [
        "#### Pretty print json/dict object"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91864d4a",
      "metadata": {
        "id": "91864d4a"
      },
      "source": [
        "Possible approaches:\n",
        "* In fact, `pandas` has `pandas.read_json(<file_dir>)` function to read json file into dataframe\n",
        "* As we create a data dict, we can also read our data dict into a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa4a5506",
      "metadata": {
        "id": "fa4a5506"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "45b0e435",
      "metadata": {
        "id": "45b0e435"
      },
      "source": [
        "### Your report\n",
        "* The total number of tweets collected in the file:\n",
        "* The content of the first tweet:\n",
        "* Is the first tweet contained any hashtags or mentions?\n",
        "* Collect all hashtags related to Thailand from this data\n",
        "* Find the most popular tweets in your collection of tweets, i.e. the tweets with the largest number of retweet/replies/likes counts\n",
        "    * You are free to define your own popularity metric\n",
        "* Display the top 5 tweets that are the most popular among your collection\n",
        "* Create a word cloud of words in the contents; however, we note that this word cloud is not a good representation of Thailand as the data size is small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b3dc416",
      "metadata": {
        "scrolled": true,
        "id": "9b3dc416"
      },
      "outputs": [],
      "source": [
        "# ----------------- Your code here -----------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2cf90e5",
      "metadata": {
        "id": "c2cf90e5"
      },
      "source": [
        "Note: ไม่ต้องรายงานส่วนนี้ในสไลด์"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccb8731c",
      "metadata": {
        "id": "ccb8731c"
      },
      "source": [
        "## Problem 2 Study Trip Advisor Hotel Reviews Sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9da6a800",
      "metadata": {
        "id": "9da6a800"
      },
      "source": [
        "We are working with the Trip Advisor Hotel Reviews dataset. You can see the source from https://www.kaggle.com/datasets/andrewmvd/trip-advisor-hotel-reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19996e72",
      "metadata": {
        "id": "19996e72"
      },
      "source": [
        "* Analyze the data to find out what make a hotel good or bad\n",
        "<br>You may create a tag of \"positive\", \"negative\", or \"neural\" sentiment first. After tagging each tweet with different sentiment, we can separate positive tweets and negative tweets. Then, it is easier to find our common patterns in positive tweets or good hotels, and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mrwoXp5kdk1R"
      },
      "id": "mrwoXp5kdk1R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "วิเคราะห์ข้อมูลเพื่อดูว่าอะไรทำให้โรงแรมดีหรือไม่ดี\n",
        "คุณสามารถสร้างแท็กความรู้สึก \"เชิงบวก\" \"เชิงลบ\" หรือ \"ปานกลาง\" ก่อนได้ หลังจากแท็กแต่ละทวีตด้วยความรู้สึกที่แตกต่างกัน เราสามารถแยกทวีตเชิงบวกและทวีตเชิงลบได้ จากนั้น จะง่ายกว่าที่จะค้นหารูปแบบทั่วไปของเราในทวีตเชิงบวกหรือโรงแรมดีๆ และในทางกลับกัน"
      ],
      "metadata": {
        "id": "B0Y4FhpUcXrw"
      },
      "id": "B0Y4FhpUcXrw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your code starts here\n",
        "- ติดป้ายกำกับแต่ละทวีตว่าเป็นความรู้สึกเชิงบวก ลบ และประสาท\n",
        "- รวมข้อความทวีตในแต่ละประเภท\n",
        "- ข้อความโทเค็น\n",
        "- แปลงเป็นตัวพิมพ์เล็ก\n",
        "- ลบคำหยุด\n",
        "- ลบคำหยุดอื่นๆ เช่น RT\n",
        "- ลบเครื่องหมายวรรคตอน\n",
        "- ลบสัญลักษณ์อื่น ๆ ออก?\n",
        "- วิเคราะห์ความถี่ของคำในแต่ละประเภทความรู้สึก เป็นต้น\n",
        "- สร้างการแสดงภาพข้อมูลสำหรับการวิเคราะห์และการนำเสนอของคุณ"
      ],
      "metadata": {
        "id": "FY2kKB5Ycq_9"
      },
      "id": "FY2kKB5Ycq_9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a55e834",
      "metadata": {
        "id": "3a55e834"
      },
      "outputs": [],
      "source": [
        "#----------------------------------------------\n",
        "# Your code starts here\n",
        "# label each tweet as positive, negative, and neural sentiment\n",
        "# combine tweet texts in each type\n",
        "# tokenize texts\n",
        "# convert to lower case\n",
        "# remove stop words\n",
        "# remove any other stop words, like RT\n",
        "# remove punctuations\n",
        "# remove other symbols?\n",
        "# analyze word frequency in each sentiment type and so on\n",
        "# create some data visualization for the analysis and your presentation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# label each tweet as positive, negative, and neural sentiment"
      ],
      "metadata": {
        "id": "53G9aRUsg8Km"
      },
      "id": "53G9aRUsg8Km"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zk4FhNS0e1I-",
        "outputId": "b651424e-2c7a-4d7a-e7d9-a657ac12381a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zk4FhNS0e1I-",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Project อ.ญา Data Warehouse and Big Data Analytics 66')\n",
        "!pwd #เช็ค path ที่กำลังทำงานอยู่"
      ],
      "metadata": {
        "id": "CMxcLdvUe7-6",
        "outputId": "43d6bead-82d2-443a-8318-310e574c1520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CMxcLdvUe7-6",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project อ.ญา Data Warehouse and Big Data Analytics 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_name = '/content/drive/MyDrive/Project อ.ญา Data Warehouse and Big Data Analytics 66/tripadvisor_hotel_reviews.xlsx' # ชื่อไฟล์ xlsx\n",
        "dfs = pd.ExcelFile(file_name) # คำสั่งอ่านไฟล์ xlsx\n",
        "dfs.sheet_names # คำสั่งเช็คว่าในไฟล์ xlsx มี seet ย่อย ในไฟล์ชื่อว่าอะไรบ้าง"
      ],
      "metadata": {
        "id": "FgB9QNZEfT02",
        "outputId": "f68b1ec4-e1e1-4c72-b9e2-d8effdb2536f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FgB9QNZEfT02",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tripadvisor_hotel_reviews']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textblob\n"
      ],
      "metadata": {
        "id": "qgkTz4dqfdA1",
        "outputId": "b9847a35-fb36-4130-a3df-c9dad74281f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qgkTz4dqfdA1",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n"
      ],
      "metadata": {
        "id": "NrGoqSkLgB7w"
      },
      "id": "NrGoqSkLgB7w",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment_label(tweet_text):\n",
        "    # Create a TextBlob object\n",
        "    analysis = TextBlob(tweet_text)\n",
        "\n",
        "    # Determine sentiment polarity (-1 to 1) and subjectivity (0 to 1)\n",
        "    sentiment_polarity = analysis.sentiment.polarity\n",
        "    sentiment_subjectivity = analysis.sentiment.subjectivity\n",
        "\n",
        "    # Define thresholds for sentiment labels\n",
        "    positive_threshold = 0.1\n",
        "    negative_threshold = -0.1\n",
        "\n",
        "    # Assign sentiment labels based on polarity\n",
        "    if sentiment_polarity > positive_threshold:\n",
        "        return \"Positive\"\n",
        "    elif sentiment_polarity < negative_threshold:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n"
      ],
      "metadata": {
        "id": "48oE9QKkgHXp"
      },
      "id": "48oE9QKkgHXp",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#combine tweet texts in each type"
      ],
      "metadata": {
        "id": "yOG7tCDGhB0Y"
      },
      "id": "yOG7tCDGhB0Y"
    },
    {
      "cell_type": "code",
      "source": [
        "# Example tweets\n",
        "tweets = [\n",
        "    \"I love this product! It's amazing!\",\n",
        "    \"This is the worst customer service I've ever experienced.\",\n",
        "    \"Just had lunch. It was okay.\",\n",
        "]\n",
        "\n",
        "# Label each tweet\n",
        "for tweet in tweets:\n",
        "    sentiment_label = get_sentiment_label(tweet)\n",
        "    print(f\"Tweet: '{tweet}'\\nSentiment: {sentiment_label}\\n\")\n"
      ],
      "metadata": {
        "id": "GYoTVl3XgJu3",
        "outputId": "f250a9d5-cd64-47fd-ef14-ea9d8bb2d263",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GYoTVl3XgJu3",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet: 'I love this product! It's amazing!'\n",
            "Sentiment: Positive\n",
            "\n",
            "Tweet: 'This is the worst customer service I've ever experienced.'\n",
            "Sentiment: Neutral\n",
            "\n",
            "Tweet: 'Just had lunch. It was okay.'\n",
            "Sentiment: Positive\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # tokenize texts"
      ],
      "metadata": {
        "id": "LydMpQZRhJ3b"
      },
      "id": "LydMpQZRhJ3b"
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Sample tweet texts\n",
        "tweets = [\n",
        "    \"I love this product! It's amazing!\",\n",
        "    \"This is the worst customer service I've ever experienced.\",\n",
        "    \"Just had lunch. It was okay.\",\n",
        "    \"I feel happy today.\",\n",
        "    \"I'm so frustrated with this traffic.\",\n",
        "    \"The weather is nice outside.\",\n",
        "    \"I'm feeling indifferent right now.\",\n",
        "]\n",
        "\n",
        "# Create empty lists for each sentiment\n",
        "positive_tweets = []\n",
        "negative_tweets = []\n",
        "neutral_tweets = []\n",
        "\n",
        "# Define a function to categorize tweets and append them to the appropriate list\n",
        "def categorize_tweets(tweet_texts):\n",
        "    for tweet_text in tweet_texts:\n",
        "        analysis = TextBlob(tweet_text)\n",
        "        sentiment_polarity = analysis.sentiment.polarity\n",
        "\n",
        "        if sentiment_polarity > 0.1:\n",
        "            positive_tweets.append(tweet_text)\n",
        "        elif sentiment_polarity < -0.1:\n",
        "            negative_tweets.append(tweet_text)\n",
        "        else:\n",
        "            neutral_tweets.append(tweet_text)\n",
        "\n",
        "# Categorize the tweets\n",
        "categorize_tweets(tweets)\n",
        "\n",
        "# Combine tweet texts for each sentiment\n",
        "combined_positive_tweets = '\\n'.join(positive_tweets)\n",
        "combined_negative_tweets = '\\n'.join(negative_tweets)\n",
        "combined_neutral_tweets = '\\n'.join(neutral_tweets)\n",
        "\n",
        "# Print the combined tweets for each sentiment\n",
        "print(\"Combined Positive Tweets:\")\n",
        "print(combined_positive_tweets)\n",
        "print(\"\\nCombined Negative Tweets:\")\n",
        "print(combined_negative_tweets)\n",
        "print(\"\\nCombined Neutral Tweets:\")\n",
        "print(combined_neutral_tweets)\n"
      ],
      "metadata": {
        "id": "xe6Vytcrg20N",
        "outputId": "20c2ac53-2823-423a-c19a-b42f1942fb61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xe6Vytcrg20N",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Positive Tweets:\n",
            "I love this product! It's amazing!\n",
            "Just had lunch. It was okay.\n",
            "I feel happy today.\n",
            "The weather is nice outside.\n",
            "I'm feeling indifferent right now.\n",
            "\n",
            "Combined Negative Tweets:\n",
            "I'm so frustrated with this traffic.\n",
            "\n",
            "Combined Neutral Tweets:\n",
            "This is the worst customer service I've ever experienced.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # convert to lower case"
      ],
      "metadata": {
        "id": "TtImSj06hY4A"
      },
      "id": "TtImSj06hY4A"
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Sample tweet texts\n",
        "tweets = [\n",
        "    \"I love this product! It's amazing!\",\n",
        "    \"This is the worst customer service I've ever experienced.\",\n",
        "    \"Just had lunch. It was okay.\",\n",
        "    \"I feel happy today.\",\n",
        "    \"I'm so frustrated with this traffic.\",\n",
        "    \"The weather is nice outside.\",\n",
        "    \"I'm feeling indifferent right now.\",\n",
        "]\n",
        "\n",
        "# Create empty lists for each sentiment\n",
        "positive_tweets = []\n",
        "negative_tweets = []\n",
        "neutral_tweets = []\n",
        "\n",
        "# Define a function to categorize tweets and append them to the appropriate list\n",
        "def categorize_tweets(tweet_texts):\n",
        "    for tweet_text in tweet_texts:\n",
        "        analysis = TextBlob(tweet_text)\n",
        "        sentiment_polarity = analysis.sentiment.polarity\n",
        "\n",
        "        if sentiment_polarity > 0.1:\n",
        "            positive_tweets.append(tweet_text.lower())  # Convert to lowercase before appending\n",
        "        elif sentiment_polarity < -0.1:\n",
        "            negative_tweets.append(tweet_text.lower())  # Convert to lowercase before appending\n",
        "        else:\n",
        "            neutral_tweets.append(tweet_text.lower())   # Convert to lowercase before appending\n",
        "\n",
        "# Categorize the tweets\n",
        "categorize_tweets(tweets)\n",
        "\n",
        "# Combine tweet texts for each sentiment\n",
        "combined_positive_tweets = '\\n'.join(positive_tweets)\n",
        "combined_negative_tweets = '\\n'.join(negative_tweets)\n",
        "combined_neutral_tweets = '\\n'.join(neutral_tweets)\n",
        "\n",
        "# Print the combined tweets for each sentiment\n",
        "print(\"Combined Positive Tweets:\")\n",
        "print(combined_positive_tweets)\n",
        "print(\"\\nCombined Negative Tweets:\")\n",
        "print(combined_negative_tweets)\n",
        "print(\"\\nCombined Neutral Tweets:\")\n",
        "print(combined_neutral_tweets)\n"
      ],
      "metadata": {
        "id": "rALVegqQhYc5",
        "outputId": "bb971b55-595a-4038-9fab-0f71ee8e7c68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rALVegqQhYc5",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Positive Tweets:\n",
            "i love this product! it's amazing!\n",
            "just had lunch. it was okay.\n",
            "i feel happy today.\n",
            "the weather is nice outside.\n",
            "i'm feeling indifferent right now.\n",
            "\n",
            "Combined Negative Tweets:\n",
            "i'm so frustrated with this traffic.\n",
            "\n",
            "Combined Neutral Tweets:\n",
            "this is the worst customer service i've ever experienced.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# remove stop words"
      ],
      "metadata": {
        "id": "k-F1qN9FhwYl"
      },
      "id": "k-F1qN9FhwYl"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk\n"
      ],
      "metadata": {
        "id": "FrBHM4bjhvx8",
        "outputId": "b4fb8272-cf96-4771-c041-252a39495ad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FrBHM4bjhvx8",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download NLTK stopwords (if not already downloaded)\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Sample tweet texts\n",
        "tweets = [\n",
        "    \"I love this product! It's amazing!\",\n",
        "    \"This is the worst customer service I've ever experienced.\",\n",
        "    \"Just had lunch. It was okay.\",\n",
        "    \"I feel happy today.\",\n",
        "    \"I'm so frustrated with this traffic.\",\n",
        "    \"The weather is nice outside.\",\n",
        "    \"I'm feeling indifferent right now.\",\n",
        "]\n",
        "\n",
        "# Create a set of stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Create empty lists for each sentiment\n",
        "positive_tweets = []\n",
        "negative_tweets = []\n",
        "neutral_tweets = []\n",
        "\n",
        "# Define a function to categorize tweets, remove stop words, and append them to the appropriate list\n",
        "def categorize_tweets(tweet_texts):\n",
        "    for tweet_text in tweet_texts:\n",
        "        analysis = TextBlob(tweet_text)\n",
        "        sentiment_polarity = analysis.sentiment.polarity\n",
        "        tweet_words = tweet_text.lower().split()  # Convert to lowercase and split into words\n",
        "\n",
        "        # Remove stop words\n",
        "        tweet_words = [word for word in tweet_words if word not in stop_words]\n",
        "        tweet_text_cleaned = ' '.join(tweet_words)\n",
        "\n",
        "        if sentiment_polarity > 0.1:\n",
        "            positive_tweets.append(tweet_text_cleaned)\n",
        "        elif sentiment_polarity < -0.1:\n",
        "            negative_tweets.append(tweet_text_cleaned)\n",
        "        else:\n",
        "            neutral_tweets.append(tweet_text_cleaned)\n",
        "\n",
        "# Categorize the tweets and remove stop words\n",
        "categorize_tweets(tweets)\n",
        "\n",
        "# Combine tweet texts for each sentiment\n",
        "combined_positive_tweets = '\\n'.join(positive_tweets)\n",
        "combined_negative_tweets = '\\n'.join(negative_tweets)\n",
        "combined_neutral_tweets = '\\n'.join(neutral_tweets)\n",
        "\n",
        "# Print the combined tweets for each sentiment\n",
        "print(\"Combined Positive Tweets (Stopwords removed):\")\n",
        "print(combined_positive_tweets)\n",
        "print(\"\\nCombined Negative Tweets (Stopwords removed):\")\n",
        "print(combined_negative_tweets)\n",
        "print(\"\\nCombined Neutral Tweets (Stopwords removed):\")\n",
        "print(combined_neutral_tweets)\n"
      ],
      "metadata": {
        "id": "erhc5PDXiAM1",
        "outputId": "c616ab9d-bf10-4575-808d-a2bd7f3382ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "erhc5PDXiAM1",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Positive Tweets (Stopwords removed):\n",
            "love product! amazing!\n",
            "lunch. okay.\n",
            "feel happy today.\n",
            "weather nice outside.\n",
            "i'm feeling indifferent right now.\n",
            "\n",
            "Combined Negative Tweets (Stopwords removed):\n",
            "i'm frustrated traffic.\n",
            "\n",
            "Combined Neutral Tweets (Stopwords removed):\n",
            "worst customer service i've ever experienced.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YVAoemEaiExN"
      },
      "id": "YVAoemEaiExN"
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download NLTK stopwords (if not already downloaded)\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Sample tweet texts\n",
        "tweets = [\n",
        "    \"I love this product! It's amazing!\",\n",
        "    \"This is the worst customer service I've ever experienced.\",\n",
        "    \"Just had lunch. It was okay.\",\n",
        "    \"I feel happy today.\",\n",
        "    \"I'm so frustrated with this traffic.\",\n",
        "    \"The weather is nice outside.\",\n",
        "    \"I'm feeling indifferent right now.\",\n",
        "    \"RT @username: Check out this article!\",\n",
        "]\n",
        "\n",
        "# Create a set of stopwords, including custom stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "custom_stop_words = set([\"rt\", \"username\"])  # Add custom stop words here\n",
        "\n",
        "# Combine the two sets of stop words\n",
        "stop_words.update(custom_stop_words)\n",
        "\n",
        "# Create empty lists for each sentiment\n",
        "positive_tweets = []\n",
        "negative_tweets = []\n",
        "neutral_tweets = []\n",
        "\n",
        "# Define a function to categorize tweets, remove stop words, and append them to the appropriate list\n",
        "def categorize_tweets(tweet_texts):\n",
        "    for tweet_text in tweet_texts:\n",
        "        analysis = TextBlob(tweet_text)\n",
        "        sentiment_polarity = analysis.sentiment.polarity\n",
        "        tweet_words = tweet_text.lower().split()  # Convert to lowercase and split into words\n",
        "\n",
        "        # Remove stop words\n",
        "        tweet_words = [word for word in tweet_words if word not in stop_words]\n",
        "        tweet_text_cleaned = ' '.join(tweet_words)\n",
        "\n",
        "        if sentiment_polarity > 0.1:\n",
        "            positive_tweets.append(tweet_text_cleaned)\n",
        "        elif sentiment_polarity < -0.1:\n",
        "            negative_tweets.append(tweet_text_cleaned)\n",
        "        else:\n",
        "            neutral_tweets.append(tweet_text_cleaned)\n",
        "\n",
        "# Categorize the tweets and remove stop words\n",
        "categorize_tweets(tweets)\n",
        "\n",
        "# Combine tweet texts for each sentiment\n",
        "combined_positive_tweets = '\\n'.join(positive_tweets)\n",
        "combined_negative_tweets = '\\n'.join(negative_tweets)\n",
        "combined_neutral_tweets = '\\n'.join(neutral_tweets)\n",
        "\n",
        "# Print the combined tweets for each sentiment\n",
        "print(\"Combined Positive Tweets (Stopwords removed):\")\n",
        "print(combined_positive_tweets)\n",
        "print(\"\\nCombined Negative Tweets (Stopwords removed):\")\n",
        "print(combined_negative_tweets)\n",
        "print(\"\\nCombined Neutral Tweets (Stopwords removed):\")\n",
        "print(combined_neutral_tweets)\n"
      ],
      "metadata": {
        "id": "MU71417HiSWQ"
      },
      "id": "MU71417HiSWQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0b4cf7eb",
      "metadata": {
        "id": "0b4cf7eb"
      },
      "source": [
        "### Report\n",
        "* How did you analyze the data?\n",
        "* What did you find in the data? (please include figures or tables in the report, but no source code)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38795f4f",
      "metadata": {
        "id": "38795f4f"
      },
      "source": [
        "## Problem 3 Collect and Analyze Your Interesting Topic"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d03d587",
      "metadata": {
        "id": "9d03d587"
      },
      "source": [
        "* Select a topic that your group members are interested\n",
        "* Gather url from at least 3 webpages\n",
        "* Use urllib.request to retrieve data from webpage\n",
        "* Clean and find intersting patterns and information\n",
        "* Create a word cloud of your topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "667c35f5",
      "metadata": {
        "id": "667c35f5"
      },
      "outputs": [],
      "source": [
        "#----------------------------------------------\n",
        "# Your code starts here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40357580",
      "metadata": {
        "id": "40357580"
      },
      "source": [
        "### Report\n",
        "* What did you find out about your topic? (please include figures or tables in the report, but no source code)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a13de1d",
      "metadata": {
        "id": "8a13de1d"
      },
      "source": [
        "# ☃️ The End of Project 1 ☃️"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}